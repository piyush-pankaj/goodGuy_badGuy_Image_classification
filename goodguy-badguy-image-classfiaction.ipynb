{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.callbacks import ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2022-11-11T07:27:27.199896Z","iopub.execute_input":"2022-11-11T07:27:27.200615Z","iopub.status.idle":"2022-11-11T07:27:35.020122Z","shell.execute_reply.started":"2022-11-11T07:27:27.200469Z","shell.execute_reply":"2022-11-11T07:27:35.019039Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nmodel = tf.keras.models.Sequential([\n                                    # The first convolution\n                                    # Input image has 3 bytes color\n                                    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(300, 300, 3)),\n                                    tf.keras.layers.MaxPooling2D(2, 2),\n                                    # The second convolution\n                                    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n                                    tf.keras.layers.MaxPooling2D(2, 2),\n                                    # The third convolution\n                                    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n                                    tf.keras.layers.MaxPooling2D(2, 2),\n                                    # The fourth convolution\n                                    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n                                    tf.keras.layers.MaxPooling2D(2, 2),\n                                    # The fifth convolution\n                                    tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n                                    tf.keras.layers.MaxPooling2D(2, 2),\n                                    # The sixth convolution\n                                    tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n                                    tf.keras.layers.MaxPooling2D(2, 2),\n                                    # Flatten the results to feed in Deep Neural Network\n                                    tf.keras.layers.Flatten(),\n                                    tf.keras.layers.Dense(512, activation=\"relu\"),\n                                    tf.keras.layers.Dense(1, activation=\"sigmoid\")                                   \n])","metadata":{"execution":{"iopub.status.busy":"2022-11-11T07:27:35.022081Z","iopub.execute_input":"2022-11-11T07:27:35.022496Z","iopub.status.idle":"2022-11-11T07:27:35.658462Z","shell.execute_reply.started":"2022-11-11T07:27:35.022372Z","shell.execute_reply":"2022-11-11T07:27:35.657143Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2022-11-11 07:27:35.492202: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-11T07:27:35.659618Z","iopub.execute_input":"2022-11-11T07:27:35.659950Z","iopub.status.idle":"2022-11-11T07:27:35.672903Z","shell.execute_reply.started":"2022-11-11T07:27:35.659919Z","shell.execute_reply":"2022-11-11T07:27:35.671505Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 298, 298, 16)      448       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 33, 33, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 14, 14, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 5, 5, 128)         147584    \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 2, 2, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 512)               0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               262656    \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 545,121\nTrainable params: 545,121\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-11-11T07:27:35.676027Z","iopub.execute_input":"2022-11-11T07:27:35.676517Z","iopub.status.idle":"2022-11-11T07:27:35.704605Z","shell.execute_reply.started":"2022-11-11T07:27:35.676454Z","shell.execute_reply":"2022-11-11T07:27:35.703723Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   fill_mode=\"nearest\")\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2022-11-11T07:27:35.706943Z","iopub.execute_input":"2022-11-11T07:27:35.707206Z","iopub.status.idle":"2022-11-11T07:27:35.715033Z","shell.execute_reply.started":"2022-11-11T07:27:35.707176Z","shell.execute_reply":"2022-11-11T07:27:35.713856Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    '../input/good-guysbad-guys-image-data-set/train',\n    target_size=(300, 300),\n    batch_size=64,\n    class_mode=\"binary\"\n)\n\n# Flow validation images in batches of 32 using validation_datagen generator\nvalidation_generator = validation_datagen.flow_from_directory(\n    '../input/good-guysbad-guys-image-data-set/test',\n    target_size=(300, 300),\n    batch_size=32, \n    class_mode=\"binary\"\n)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n\n# model.fit(x = train_generator,validation_data = validation_generator, callbacks= reduce_lr)\n\nhistory = model.fit(train_generator,\n                         steps_per_epoch = 50,\n                         epochs = 10,\n                         validation_data = validation_generator,\n                         validation_steps = 8)","metadata":{"execution":{"iopub.status.busy":"2022-11-11T07:27:35.716395Z","iopub.execute_input":"2022-11-11T07:27:35.716679Z","iopub.status.idle":"2022-11-11T07:58:47.665216Z","shell.execute_reply.started":"2022-11-11T07:27:35.716650Z","shell.execute_reply":"2022-11-11T07:58:47.664212Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 11220 images belonging to 2 classes.\nFound 600 images belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"2022-11-11 07:27:43.400118: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n50/50 [==============================] - 154s 3s/step - loss: 0.6890 - accuracy: 0.5269 - val_loss: 0.6543 - val_accuracy: 0.6094\nEpoch 2/10\n50/50 [==============================] - 150s 3s/step - loss: 0.6651 - accuracy: 0.5844 - val_loss: 0.5794 - val_accuracy: 0.6094\nEpoch 3/10\n50/50 [==============================] - 147s 3s/step - loss: 0.6574 - accuracy: 0.5745 - val_loss: 0.5631 - val_accuracy: 0.6680\nEpoch 4/10\n50/50 [==============================] - 147s 3s/step - loss: 0.6325 - accuracy: 0.6303 - val_loss: 0.5152 - val_accuracy: 0.7500\nEpoch 5/10\n50/50 [==============================] - 147s 3s/step - loss: 0.6165 - accuracy: 0.6575 - val_loss: 0.5232 - val_accuracy: 0.7617\nEpoch 6/10\n50/50 [==============================] - 143s 3s/step - loss: 0.5859 - accuracy: 0.6744 - val_loss: 0.4591 - val_accuracy: 0.7852\nEpoch 7/10\n50/50 [==============================] - 145s 3s/step - loss: 0.5677 - accuracy: 0.6978 - val_loss: 0.4478 - val_accuracy: 0.7852\nEpoch 8/10\n50/50 [==============================] - 144s 3s/step - loss: 0.5220 - accuracy: 0.7328 - val_loss: 0.4048 - val_accuracy: 0.8281\nEpoch 9/10\n50/50 [==============================] - 145s 3s/step - loss: 0.5268 - accuracy: 0.7306 - val_loss: 0.4420 - val_accuracy: 0.7891\nEpoch 10/10\n50/50 [==============================] - 144s 3s/step - loss: 0.5182 - accuracy: 0.7469 - val_loss: 0.4392 - val_accuracy: 0.8086\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.preprocessing import image\nimport numpy as np\n# Predicting Images\npath = input()\nimg = image.load_img(path, target_size=(300,300))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\n\nimages = np.vstack([x])\nclasses = model.predict(images, batch_size=10)\nprint(classes[0]) \nif classes[0] > 0.5:\n    print(img, \"is  bad guy\")\nelse:\n    print(img, \"is  good guy\")","metadata":{"execution":{"iopub.status.busy":"2022-11-11T10:00:54.344576Z","iopub.execute_input":"2022-11-11T10:00:54.345478Z","iopub.status.idle":"2022-11-11T10:00:59.632102Z","shell.execute_reply.started":"2022-11-11T10:00:54.345434Z","shell.execute_reply":"2022-11-11T10:00:59.631067Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdin","text":" ../input/dfghjk/Screenshot 2022-04-18 at 1.20.44 PM.png\n"},{"name":"stdout","text":"[1.]\n<PIL.Image.Image image mode=RGB size=300x300 at 0x7F2F6C976950> is  bad guy\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}